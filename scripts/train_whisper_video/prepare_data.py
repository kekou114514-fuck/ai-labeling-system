import json
import os
import sys
import pandas as pd
import soundfile as sf
import librosa
from tqdm import tqdm
import urllib.parse 

sys.stdout.reconfigure(line_buffering=True)

# === é…ç½® ===
DATA_ROOT = os.getenv('DATA_ROOT', '/data')
EXPORT_FILE = "./project_export.json" 
AUDIO_DIR = os.path.join(DATA_ROOT, "video_audio")  
OUTPUT_DIR = "./dataset"
METADATA_PATH = os.path.join(OUTPUT_DIR, "metadata.csv")

def prepare_dataset():
    # æ¸…ç†æ—§æ•°æ®
    if os.path.exists(METADATA_PATH): os.remove(METADATA_PATH)
    os.makedirs(os.path.join(OUTPUT_DIR, "audio"), exist_ok=True)

    if not os.path.exists(EXPORT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°å¯¼å‡ºæ–‡ä»¶ {EXPORT_FILE}")
        sys.exit(1)

    with open(EXPORT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    metadata = []
    print(f"ðŸ” [è¯Šæ–­æ¨¡å¼] å¼€å§‹æ£€æŸ¥ {len(data)} ä¸ªä»»åŠ¡...")
    print(f"ðŸ“‚ éŸ³é¢‘æºç›®å½•: {AUDIO_DIR}")

    for task in data:
        task_id = task.get('id')
        print(f"\nðŸ“‹ --- æ£€æŸ¥ä»»åŠ¡ Task {task_id} ---")
        
        # 1. æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
        audio_url = task.get('data', {}).get('audio', '')
        if not audio_url: 
            print(f"   âŒ å¤±è´¥: æ²¡æœ‰éŸ³é¢‘ URL")
            continue
            
        decoded_url = urllib.parse.unquote(audio_url)
        fname = os.path.basename(decoded_url.split("?d=")[-1] if "?d=" in decoded_url else decoded_url)
        audio_path = os.path.join(AUDIO_DIR, fname)
        
        if not os.path.exists(audio_path):
            print(f"   âŒ å¤±è´¥: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ ({audio_path})")
            continue
        else:
            print(f"   âœ… éŸ³é¢‘æ–‡ä»¶å­˜åœ¨: {fname}")

        # 2. æ£€æŸ¥æ ‡æ³¨
        if not task.get('annotations'):
            print(f"   âŒ å¤±è´¥: è¿™ä¸ªä»»åŠ¡æ²¡æœ‰ä»»ä½•æ ‡æ³¨ (Annotations ä¸ºç©º)")
            continue

        valid_count_in_task = 0
        try:
            # åŠ è½½éŸ³é¢‘èŽ·å–æ—¶é•¿
            y, sr = librosa.load(audio_path, sr=16000)
            audio_len_sec = len(y) / sr

            for ann in task.get('annotations', []):
                results = ann.get('result', [])
                if not results:
                    print(f"   âš ï¸ è­¦å‘Š: æ ‡æ³¨ç»“æžœ (result) æ˜¯ç©ºçš„")
                
                for i, res in enumerate(results):
                    r_type = res.get('type')
                    print(f"   ðŸ§ [Result {i}] ç±»åž‹: {r_type}")
                    
                    # æˆ‘ä»¬åªå…³å¿ƒ 'textarea' (æ–‡æœ¬è½¬å†™)
                    if r_type != 'textarea':
                        print(f"      -> è·³è¿‡ (åŽŸå› : æˆ‘ä»¬éœ€è¦ 'textarea' ç±»åž‹æ¥è®­ç»ƒ Whisperï¼Œè€Œè¿™æ˜¯ '{r_type}')")
                        continue
                    
                    # æ£€æŸ¥æ–‡æœ¬å†…å®¹
                    text_val = res.get('value', {}).get('text', [])
                    text = text_val[0].strip() if text_val else ""
                    print(f"      -> æ–‡æœ¬å†…å®¹: '{text}'")
                    
                    if not text:
                        print(f"      âŒ å¤±è´¥: æ–‡æœ¬æ˜¯ç©ºçš„")
                        continue
                    if "æ­£åœ¨è½¬å†™" in text or "åœ¨æ­¤è¾“å…¥" in text:
                        print(f"      âŒ å¤±è´¥: æ–‡æœ¬åŒ…å«é»˜è®¤å ä½ç¬¦")
                        continue
                        
                    # æ£€æŸ¥æ—¶é—´æˆ³
                    start = res['value'].get('start', 0)
                    end = res['value'].get('end', audio_len_sec)
                    duration = end - start
                    print(f"      -> æ—¶é—´æ®µ: {start:.2f}s - {end:.2f}s (æ—¶é•¿: {duration:.2f}s)")
                    
                    if duration < 0.1:
                        print(f"      âŒ å¤±è´¥: ç‰‡æ®µå¤ªçŸ­ (<0.1s)")
                        continue

                    # ä¸€åˆ‡æ­£å¸¸ï¼Œä¿å­˜åˆ‡ç‰‡
                    start_sample = int(start * sr)
                    end_sample = int(end * sr)
                    y_chunk = y[start_sample:end_sample]
                    
                    chunk_name = f"task{task_id}_{res['id']}.wav"
                    save_path = os.path.join(OUTPUT_DIR, "audio", chunk_name)
                    sf.write(save_path, y_chunk, sr)
                    
                    metadata.append({"file_name": f"audio/{chunk_name}", "sentence": text})
                    valid_count_in_task += 1
                    print(f"      âœ… æˆåŠŸæå–ï¼")

        except Exception as e:
            print(f"   âŒ å¤„ç†å¼‚å¸¸: {e}")

    # æ€»ç»“
    print("\n" + "="*30)
    if metadata:
        pd.DataFrame(metadata).to_csv(METADATA_PATH, index=False)
        print(f"ðŸŽ‰ æœ€ç»ˆæˆåŠŸå‡†å¤‡äº† {len(metadata)} æ¡æ•°æ®ï¼")
    else:
        print("ðŸ›‘ è‡´å‘½é”™è¯¯: æœ‰æ•ˆæ•°æ®ä¸º 0ã€‚è¯·æ ¹æ®ä¸Šæ–¹çš„ 'âŒ å¤±è´¥' æç¤ºåŽ» Label Studio ä¿®æ”¹æ ‡æ³¨ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    prepare_dataset()
